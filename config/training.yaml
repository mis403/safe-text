# 敏感词检测模型训练配置
# 直接编辑此文件即可修改训练参数

# 模型配置
model:
  name: "xlm-roberta-base"
  max_length: 512
  num_labels: 2

# 训练参数 - 优化调整版
training:
  # 基础参数
  batch_size: 8
  learning_rate: 0.00002          # 稍微降低学习率，寻求更稳定的收敛 (2e-5)
  num_epochs: 3
  
  # 防过拟合参数 (保持不变，已经很好了)
  weight_decay: 0.1
  max_grad_norm: 1.0
  label_smoothing_factor: 0.1
  
  # 早停配置 - 放宽条件
  early_stopping_patience: 5       # 增加耐心，从 2 -> 5
  early_stopping_threshold: 0.001    # 降低敏感度，从 0.005 -> 0.001
  
  # 学习率调度
  warmup_steps: 100
  warmup_ratio: 0.1                # warmup_steps 和 warmup_ratio 通常只用一个，HuggingFace Trainer 优先使用 ratio
  lr_scheduler_type: "linear"      # 改为更平滑的线性衰减
  
  # 梯度和内存优化 (保持不变)
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  
  # 评估和保存 - 降低频率
  eval_strategy: "steps"
  eval_steps: 200                  # 显著增加评估间隔，从 50 -> 200 (请根据你的数据量调整)
  save_strategy: "steps"
  save_steps: 200                  # 保持与 eval_steps 一致
  logging_steps: 50                # 日志可以频繁一些，方便观察
  
  # 模型选择 (保持不变)
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  
  # 数据加载优化 (保持不变)
  dataloader_pin_memory: true
  dataloader_drop_last: true
  remove_unused_columns: true
  
  # 随机种子 (保持不变)
  seed: 42

# 数据配置 - 方案B：最大化训练数据
data:
  train_ratio: 0.9                 # 训练集比例 (90% - 最大化训练数据)
  val_ratio: 0.05                  # 验证集比例 (5% - 足够验证)
  test_ratio: 0.05                 # 测试集比例 (5% - 足够测试)
  random_seed: 42                  # 数据分割随机种子

# 快速配置预设 (注释掉不使用的)
presets:
 