#!/usr/bin/env python3
"""
äº¤äº’å¼æµ‹è¯•è„šæœ¬ - è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€æ–°è®­ç»ƒå¥½çš„æ¨¡å‹
"""

import sys
import os
from pathlib import Path
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.models.inference import SensitiveWordInference
from src.utils.logger import setup_logger
from src.utils.model_finder import find_latest_model, get_model_info
from config.settings import config

logger = setup_logger(__name__)

class InteractiveModelTester:
    """äº¤äº’å¼æ¨¡å‹æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.inference_engine = None
        self.model_path = None
        
    def find_latest_model(self):
        """è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ¨¡å‹"""
        print("ğŸ” æ­£åœ¨æŸ¥æ‰¾æœ€æ–°è®­ç»ƒçš„æ¨¡å‹...")
        
        model_path = find_latest_model()
        if model_path:
            # è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯
            model_info = get_model_info(model_path)
            
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_path}")
            print(f"   è®­ç»ƒæ—¶é—´: {model_info.get('modified_time_str', 'æœªçŸ¥')}")
            print(f"   æ¨¡å‹ç±»å‹: {model_info.get('model_type', 'æœªçŸ¥')}")
            
            self.model_path = model_path
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            print("   è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python3 train.py")
            return False
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if not self.model_path:
            if not self.find_latest_model():
                return False
        
        try:
            print(f"ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
            
            self.inference_engine = SensitiveWordInference(
                model_path=self.model_path,
                use_rules=False,  # åªä½¿ç”¨AIæ¨¡å‹
                use_ai=True
            )
            
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def show_model_info(self):
        """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
        if not self.inference_engine:
            return
        
        print("\n" + "="*50)
        print("ğŸ“Š æ¨¡å‹ä¿¡æ¯")
        print("="*50)
        print(f"æ¨¡å‹è·¯å¾„: {self.model_path}")
        print(f"è®¾å¤‡: {self.inference_engine.device}")
        print(f"æœ€å¤§é•¿åº¦: {config.model_config['max_length']}")
        print(f"ç½®ä¿¡åº¦é˜ˆå€¼: 0.5 (é»˜è®¤)")
        print("="*50)
    
    def predict_text(self, text):
        """é¢„æµ‹å•ä¸ªæ–‡æœ¬"""
        if not self.inference_engine:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None
        
        try:
            result = self.inference_engine.predict_single(text, return_probabilities=True)
            return result
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def format_result(self, result, text):
        """æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœ"""
        if not result:
            return
        
        print(f"\nğŸ“ è¾“å…¥æ–‡æœ¬: {text}")
        print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print("-" * 50)
        
        # åŸºæœ¬ç»“æœ
        is_sensitive = result.get('is_sensitive', False)
        confidence = result.get('confidence', 0)
        final_decision = result.get('final_decision', 'unknown')
        
        # çŠ¶æ€æ˜¾ç¤º
        status_icon = "ğŸš¨" if is_sensitive else "âœ…"
        status_text = "æ•æ„Ÿå†…å®¹" if is_sensitive else "æ­£å¸¸å†…å®¹"
        
        print(f"{status_icon} æ£€æµ‹ç»“æœ: {status_text}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.4f}")
        print(f"ğŸ“Š æœ€ç»ˆå†³ç­–: {final_decision}")
        
        # AIè¯¦ç»†ç»“æœ
        ai_result = result.get('ai_result')
        if ai_result:
            print(f"\nğŸ¤– AIæ¨¡å‹è¯¦æƒ…:")
            print(f"   é¢„æµ‹ç±»åˆ«: {ai_result.get('prediction', 'N/A')}")
            print(f"   æ ‡ç­¾: {ai_result.get('label', 'N/A')}")
            print(f"   ç½®ä¿¡åº¦: {ai_result.get('confidence', 0):.4f}")
            
            # æ¦‚ç‡åˆ†å¸ƒ
            probabilities = ai_result.get('probabilities', {})
            if probabilities:
                print(f"   æ¦‚ç‡åˆ†å¸ƒ:")
                for label, prob in probabilities.items():
                    print(f"     {label}: {prob:.4f}")
        
        print("-" * 50)
    
    def run_batch_test(self):
        """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
        print("\nğŸ§ª æ‰¹é‡æµ‹è¯•æ¨¡å¼")
        print("è¯·è¾“å…¥å¤šä¸ªæ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸ:")
        
        texts = []
        while True:
            text = input("æ–‡æœ¬: ").strip()
            if not text:
                break
            texts.append(text)
        
        if not texts:
            print("âŒ æ²¡æœ‰è¾“å…¥æ–‡æœ¬")
            return
        
        print(f"\nğŸš€ æ­£åœ¨å¤„ç† {len(texts)} ä¸ªæ–‡æœ¬...")
        
        try:
            results = self.inference_engine.predict_batch(texts)
            
            print(f"\nğŸ“Š æ‰¹é‡æµ‹è¯•ç»“æœ:")
            print("="*60)
            
            sensitive_count = 0
            for i, result in enumerate(results, 1):
                text = result['text']
                is_sensitive = result['is_sensitive']
                confidence = result['confidence']
                
                if is_sensitive:
                    sensitive_count += 1
                
                status_icon = "ğŸš¨" if is_sensitive else "âœ…"
                status_text = "æ•æ„Ÿ" if is_sensitive else "æ­£å¸¸"
                
                print(f"{i:2d}. {status_icon} {text[:30]}{'...' if len(text) > 30 else ''}")
                print(f"     ç»“æœ: {status_text} (ç½®ä¿¡åº¦: {confidence:.4f})")
            
            print("="*60)
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ€»æ•°: {len(results)}")
            print(f"   æ•æ„Ÿ: {sensitive_count}")
            print(f"   æ­£å¸¸: {len(results) - sensitive_count}")
            print(f"   æ•æ„Ÿæ¯”ä¾‹: {sensitive_count/len(results)*100:.1f}%")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")
    
    def run_interactive_mode(self):
        """è¿è¡Œäº¤äº’å¼æ¨¡å¼"""
        print("\nğŸ’¬ äº¤äº’å¼æµ‹è¯•æ¨¡å¼")
        print("è¾“å…¥æ–‡æœ¬è¿›è¡Œæ£€æµ‹ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("è¾“å…¥ 'batch' è¿›å…¥æ‰¹é‡æµ‹è¯•æ¨¡å¼")
        print("è¾“å…¥ 'info' æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯")
        print("-" * 50)
        
        while True:
            try:
                text = input("\nè¯·è¾“å…¥æ–‡æœ¬: ").strip()
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºåŸå§‹è¾“å…¥
                print(f"[è°ƒè¯•] åŸå§‹è¾“å…¥: '{text}' (é•¿åº¦: {len(text)})")
                
                if not text:
                    continue
                
                # ç‰¹æ®Šå‘½ä»¤
                if text.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è§!")
                    break
                elif text.lower() == 'batch':
                    self.run_batch_test()
                    continue
                elif text.lower() == 'info':
                    self.show_model_info()
                    continue
                
                # é¢„æµ‹æ–‡æœ¬
                result = self.predict_text(text)
                self.format_result(result, text)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
    
    def run_preset_tests(self):
        """è¿è¡Œé¢„è®¾æµ‹è¯•ç”¨ä¾‹"""
        print("\nğŸ§ª è¿è¡Œé¢„è®¾æµ‹è¯•ç”¨ä¾‹...")
        
        test_cases = [
            "è¿™æ˜¯ä¸€æ®µæ­£å¸¸çš„æ–‡æœ¬å†…å®¹",
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥",
            "æˆ‘å–œæ¬¢å­¦ä¹ äººå·¥æ™ºèƒ½æŠ€æœ¯",
            "Pythonæ˜¯ä¸€é—¨å¾ˆæ£’çš„ç¼–ç¨‹è¯­è¨€",
            "æœºå™¨å­¦ä¹ è®©ä¸–ç•Œå˜å¾—æ›´ç¾å¥½",
            "æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å‡†ç¡®ç‡å¾ˆé«˜",
            "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å‘å±•è¿…é€Ÿ",
            "è¿™ä¸ªé¡¹ç›®çš„ä»£ç å†™å¾—å¾ˆå¥½",
            "æ•°æ®ç§‘å­¦æ˜¯ä¸€ä¸ªæœ‰è¶£çš„é¢†åŸŸ",
            "ç®—æ³•ä¼˜åŒ–å¯ä»¥æå‡æ€§èƒ½"
        ]
        
        print(f"æ­£åœ¨æµ‹è¯• {len(test_cases)} ä¸ªé¢„è®¾ç”¨ä¾‹...")
        
        try:
            results = self.inference_engine.predict_batch(test_cases)
            
            print(f"\nğŸ“Š é¢„è®¾æµ‹è¯•ç»“æœ:")
            print("="*70)
            
            for i, result in enumerate(results, 1):
                text = result['text']
                is_sensitive = result['is_sensitive']
                confidence = result['confidence']
                
                status_icon = "ğŸš¨" if is_sensitive else "âœ…"
                status_text = "æ•æ„Ÿ" if is_sensitive else "æ­£å¸¸"
                
                print(f"{i:2d}. {text}")
                print(f"    {status_icon} {status_text} (ç½®ä¿¡åº¦: {confidence:.4f})")
            
            # ç»Ÿè®¡ä¿¡æ¯
            sensitive_count = sum(1 for r in results if r['is_sensitive'])
            avg_confidence = sum(r['confidence'] for r in results) / len(results)
            
            print("="*70)
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ•æ„Ÿæ–‡æœ¬: {sensitive_count}/{len(results)}")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f}")
            
        except Exception as e:
            print(f"âŒ é¢„è®¾æµ‹è¯•å¤±è´¥: {e}")
    
    def show_menu(self):
        """æ˜¾ç¤ºä¸»èœå•"""
        print("\n" + "="*50)
        print("ğŸ¯ æ•æ„Ÿè¯æ£€æµ‹ - äº¤äº’å¼æµ‹è¯•")
        print("="*50)
        print("1. äº¤äº’å¼æµ‹è¯• (æ¨è)")
        print("2. æ‰¹é‡æµ‹è¯•")
        print("3. é¢„è®¾æµ‹è¯•ç”¨ä¾‹")
        print("4. æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯")
        print("5. é€€å‡º")
        print("="*50)
    
    def run(self):
        """è¿è¡Œæµ‹è¯•å™¨"""
        print("ğŸš€ å¯åŠ¨äº¤äº’å¼æ¨¡å‹æµ‹è¯•å™¨...")
        
        # åŠ è½½æ¨¡å‹
        if not self.load_model():
            return
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        self.show_model_info()
        
        # ä¸»å¾ªç¯
        while True:
            self.show_menu()
            
            try:
                choice = input("è¯·é€‰æ‹©æ“ä½œ (1-5): ").strip()
                
                if choice == '1':
                    self.run_interactive_mode()
                elif choice == '2':
                    self.run_batch_test()
                elif choice == '3':
                    self.run_preset_tests()
                elif choice == '4':
                    self.show_model_info()
                elif choice == '5':
                    print("ğŸ‘‹ å†è§!")
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-5")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='äº¤äº’å¼æ•æ„Ÿè¯æ£€æµ‹æµ‹è¯•')
    parser.add_argument('model_path', nargs='?', help='æŒ‡å®šæ¨¡å‹è·¯å¾„ (å¯é€‰)')
    
    args = parser.parse_args()
    
    tester = InteractiveModelTester()
    
    # å¦‚æœæŒ‡å®šäº†æ¨¡å‹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
    if args.model_path:
        print(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {args.model_path}")
        tester.model_path = args.model_path
    
    tester.run()

if __name__ == "__main__":
    main()
